{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/3.7.0/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/var/pyenv/versions/3.7.0/lib/python3.7/site-packages/lightgbm/engine.py:118: UserWarning: Found `num_iteration` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.973556\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 0.85077\n",
      "[3]\tvalid_0's multi_logloss: 0.747695\n",
      "[4]\tvalid_0's multi_logloss: 0.659992\n",
      "[5]\tvalid_0's multi_logloss: 0.584612\n",
      "[6]\tvalid_0's multi_logloss: 0.519314\n",
      "[7]\tvalid_0's multi_logloss: 0.462397\n",
      "[8]\tvalid_0's multi_logloss: 0.412533\n",
      "[9]\tvalid_0's multi_logloss: 0.368666\n",
      "[10]\tvalid_0's multi_logloss: 0.330635\n",
      "[11]\tvalid_0's multi_logloss: 0.296283\n",
      "[12]\tvalid_0's multi_logloss: 0.266398\n",
      "[13]\tvalid_0's multi_logloss: 0.239211\n",
      "[14]\tvalid_0's multi_logloss: 0.215719\n",
      "[15]\tvalid_0's multi_logloss: 0.194743\n",
      "[16]\tvalid_0's multi_logloss: 0.175988\n",
      "[17]\tvalid_0's multi_logloss: 0.159196\n",
      "[18]\tvalid_0's multi_logloss: 0.144146\n",
      "[19]\tvalid_0's multi_logloss: 0.130642\n",
      "[20]\tvalid_0's multi_logloss: 0.118517\n",
      "[21]\tvalid_0's multi_logloss: 0.10762\n",
      "[22]\tvalid_0's multi_logloss: 0.0973694\n",
      "[23]\tvalid_0's multi_logloss: 0.0885296\n",
      "[24]\tvalid_0's multi_logloss: 0.0801618\n",
      "[25]\tvalid_0's multi_logloss: 0.0729727\n",
      "[26]\tvalid_0's multi_logloss: 0.0664935\n",
      "[27]\tvalid_0's multi_logloss: 0.0606518\n",
      "[28]\tvalid_0's multi_logloss: 0.0553831\n",
      "[29]\tvalid_0's multi_logloss: 0.050216\n",
      "[30]\tvalid_0's multi_logloss: 0.0455475\n",
      "[31]\tvalid_0's multi_logloss: 0.0413287\n",
      "[32]\tvalid_0's multi_logloss: 0.0375158\n",
      "[33]\tvalid_0's multi_logloss: 0.0340691\n",
      "[34]\tvalid_0's multi_logloss: 0.0309533\n",
      "[35]\tvalid_0's multi_logloss: 0.0281362\n",
      "[36]\tvalid_0's multi_logloss: 0.025589\n",
      "[37]\tvalid_0's multi_logloss: 0.0234106\n",
      "[38]\tvalid_0's multi_logloss: 0.0214414\n",
      "[39]\tvalid_0's multi_logloss: 0.0196612\n",
      "[40]\tvalid_0's multi_logloss: 0.0180517\n",
      "[41]\tvalid_0's multi_logloss: 0.0165964\n",
      "[42]\tvalid_0's multi_logloss: 0.0152804\n",
      "[43]\tvalid_0's multi_logloss: 0.0140903\n",
      "[44]\tvalid_0's multi_logloss: 0.0128231\n",
      "[45]\tvalid_0's multi_logloss: 0.0116757\n",
      "[46]\tvalid_0's multi_logloss: 0.0106367\n",
      "[47]\tvalid_0's multi_logloss: 0.00969594\n",
      "[48]\tvalid_0's multi_logloss: 0.00884424\n",
      "[49]\tvalid_0's multi_logloss: 0.00807318\n",
      "[50]\tvalid_0's multi_logloss: 0.00737515\n",
      "[51]\tvalid_0's multi_logloss: 0.00674326\n",
      "[52]\tvalid_0's multi_logloss: 0.00617126\n",
      "[53]\tvalid_0's multi_logloss: 0.0056535\n",
      "[54]\tvalid_0's multi_logloss: 0.00518485\n",
      "[55]\tvalid_0's multi_logloss: 0.00476067\n",
      "[56]\tvalid_0's multi_logloss: 0.00437674\n",
      "[57]\tvalid_0's multi_logloss: 0.00402925\n",
      "[58]\tvalid_0's multi_logloss: 0.00371382\n",
      "[59]\tvalid_0's multi_logloss: 0.00342292\n",
      "[60]\tvalid_0's multi_logloss: 0.00315962\n",
      "[61]\tvalid_0's multi_logloss: 0.00285972\n",
      "[62]\tvalid_0's multi_logloss: 0.00263809\n",
      "[63]\tvalid_0's multi_logloss: 0.00243821\n",
      "[64]\tvalid_0's multi_logloss: 0.00225732\n",
      "[65]\tvalid_0's multi_logloss: 0.0020936\n",
      "[66]\tvalid_0's multi_logloss: 0.00194543\n",
      "[67]\tvalid_0's multi_logloss: 0.00181134\n",
      "[68]\tvalid_0's multi_logloss: 0.00168999\n",
      "[69]\tvalid_0's multi_logloss: 0.0015305\n",
      "[70]\tvalid_0's multi_logloss: 0.00141363\n",
      "[71]\tvalid_0's multi_logloss: 0.00128109\n",
      "[72]\tvalid_0's multi_logloss: 0.00115944\n",
      "[73]\tvalid_0's multi_logloss: 0.00105086\n",
      "[74]\tvalid_0's multi_logloss: 0.000951032\n",
      "[75]\tvalid_0's multi_logloss: 0.000862111\n",
      "[76]\tvalid_0's multi_logloss: 0.000780188\n",
      "[77]\tvalid_0's multi_logloss: 0.000717837\n",
      "[78]\tvalid_0's multi_logloss: 0.000649995\n",
      "[79]\tvalid_0's multi_logloss: 0.000596027\n",
      "[80]\tvalid_0's multi_logloss: 0.000546779\n",
      "[81]\tvalid_0's multi_logloss: 0.000501824\n",
      "[82]\tvalid_0's multi_logloss: 0.000460774\n",
      "[83]\tvalid_0's multi_logloss: 0.000425679\n",
      "[84]\tvalid_0's multi_logloss: 0.000392511\n",
      "[85]\tvalid_0's multi_logloss: 0.000362128\n",
      "[86]\tvalid_0's multi_logloss: 0.000338484\n",
      "[87]\tvalid_0's multi_logloss: 0.000307711\n",
      "[88]\tvalid_0's multi_logloss: 0.000288161\n",
      "[89]\tvalid_0's multi_logloss: 0.000262572\n",
      "[90]\tvalid_0's multi_logloss: 0.000239351\n",
      "[91]\tvalid_0's multi_logloss: 0.000218276\n",
      "[92]\tvalid_0's multi_logloss: 0.00020487\n",
      "[93]\tvalid_0's multi_logloss: 0.000186385\n",
      "[94]\tvalid_0's multi_logloss: 0.000170183\n",
      "[95]\tvalid_0's multi_logloss: 0.000155484\n",
      "[96]\tvalid_0's multi_logloss: 0.000143764\n",
      "[97]\tvalid_0's multi_logloss: 0.000131529\n",
      "[98]\tvalid_0's multi_logloss: 0.000120566\n",
      "[99]\tvalid_0's multi_logloss: 0.000114026\n",
      "[100]\tvalid_0's multi_logloss: 0.000104721\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.000104721\n"
     ]
    }
   ],
   "source": [
    "# LightGBM parameters\n",
    "params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'multiclass',\n",
    "        'metric': {'multi_logloss'},\n",
    "        'num_class': 3,\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 23,\n",
    "        'min_data_in_leaf': 1,\n",
    "        'num_iteration': 100,\n",
    "        'verbose': 0\n",
    "}\n",
    "\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "            lgb_train,\n",
    "            num_boost_round=50,\n",
    "            valid_sets=lgb_eval,\n",
    "            early_stopping_rounds=10)\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston Housing: regression\n",
      "[1]\tvalid_0's l2: 68.0766\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's l2: 58.5319\n",
      "[3]\tvalid_0's l2: 50.6052\n",
      "[4]\tvalid_0's l2: 44.2466\n",
      "[5]\tvalid_0's l2: 39.0957\n",
      "[6]\tvalid_0's l2: 34.6924\n",
      "[7]\tvalid_0's l2: 31.0212\n",
      "[8]\tvalid_0's l2: 28.2217\n",
      "[9]\tvalid_0's l2: 25.7956\n",
      "[10]\tvalid_0's l2: 23.5496\n",
      "[11]\tvalid_0's l2: 21.583\n",
      "[12]\tvalid_0's l2: 19.7445\n",
      "[13]\tvalid_0's l2: 18.6855\n",
      "[14]\tvalid_0's l2: 17.658\n",
      "[15]\tvalid_0's l2: 16.9647\n",
      "[16]\tvalid_0's l2: 16.3728\n",
      "[17]\tvalid_0's l2: 15.7672\n",
      "[18]\tvalid_0's l2: 14.9607\n",
      "[19]\tvalid_0's l2: 14.3419\n",
      "[20]\tvalid_0's l2: 13.9365\n",
      "[21]\tvalid_0's l2: 13.6606\n",
      "[22]\tvalid_0's l2: 13.4356\n",
      "[23]\tvalid_0's l2: 13.1265\n",
      "[24]\tvalid_0's l2: 13.0407\n",
      "[25]\tvalid_0's l2: 13.0223\n",
      "[26]\tvalid_0's l2: 12.6694\n",
      "[27]\tvalid_0's l2: 12.3531\n",
      "[28]\tvalid_0's l2: 12.2361\n",
      "[29]\tvalid_0's l2: 12.0349\n",
      "[30]\tvalid_0's l2: 11.8093\n",
      "[31]\tvalid_0's l2: 11.7095\n",
      "[32]\tvalid_0's l2: 11.6674\n",
      "[33]\tvalid_0's l2: 11.5441\n",
      "[34]\tvalid_0's l2: 11.5095\n",
      "[35]\tvalid_0's l2: 11.2841\n",
      "[36]\tvalid_0's l2: 11.2055\n",
      "[37]\tvalid_0's l2: 11.1762\n",
      "[38]\tvalid_0's l2: 11.0989\n",
      "[39]\tvalid_0's l2: 11.0993\n",
      "[40]\tvalid_0's l2: 11.061\n",
      "[41]\tvalid_0's l2: 10.9074\n",
      "[42]\tvalid_0's l2: 10.7896\n",
      "[43]\tvalid_0's l2: 10.651\n",
      "[44]\tvalid_0's l2: 10.5997\n",
      "[45]\tvalid_0's l2: 10.5713\n",
      "[46]\tvalid_0's l2: 10.5134\n",
      "[47]\tvalid_0's l2: 10.3927\n",
      "[48]\tvalid_0's l2: 10.3503\n",
      "[49]\tvalid_0's l2: 10.2809\n",
      "[50]\tvalid_0's l2: 10.2425\n",
      "[51]\tvalid_0's l2: 10.2234\n",
      "[52]\tvalid_0's l2: 10.1286\n",
      "[53]\tvalid_0's l2: 10.0608\n",
      "[54]\tvalid_0's l2: 10.0826\n",
      "[55]\tvalid_0's l2: 10.084\n",
      "[56]\tvalid_0's l2: 10.0847\n",
      "[57]\tvalid_0's l2: 10.1138\n",
      "[58]\tvalid_0's l2: 10.1433\n",
      "[59]\tvalid_0's l2: 10.0968\n",
      "[60]\tvalid_0's l2: 10.0515\n",
      "[61]\tvalid_0's l2: 10.0183\n",
      "[62]\tvalid_0's l2: 9.97108\n",
      "[63]\tvalid_0's l2: 9.94242\n",
      "[64]\tvalid_0's l2: 9.93813\n",
      "[65]\tvalid_0's l2: 9.94055\n",
      "[66]\tvalid_0's l2: 9.9198\n",
      "[67]\tvalid_0's l2: 9.86796\n",
      "[68]\tvalid_0's l2: 9.89736\n",
      "[69]\tvalid_0's l2: 9.89245\n",
      "[70]\tvalid_0's l2: 9.86818\n",
      "[71]\tvalid_0's l2: 9.85639\n",
      "[72]\tvalid_0's l2: 9.84668\n",
      "[73]\tvalid_0's l2: 9.88095\n",
      "[74]\tvalid_0's l2: 9.89604\n",
      "[75]\tvalid_0's l2: 9.92519\n",
      "[76]\tvalid_0's l2: 9.93288\n",
      "[77]\tvalid_0's l2: 9.82229\n",
      "[78]\tvalid_0's l2: 9.79787\n",
      "[79]\tvalid_0's l2: 9.75904\n",
      "[80]\tvalid_0's l2: 9.69879\n",
      "[81]\tvalid_0's l2: 9.75144\n",
      "[82]\tvalid_0's l2: 9.7899\n",
      "[83]\tvalid_0's l2: 9.82924\n",
      "[84]\tvalid_0's l2: 9.88303\n",
      "[85]\tvalid_0's l2: 9.88663\n",
      "[86]\tvalid_0's l2: 9.85619\n",
      "[87]\tvalid_0's l2: 9.8057\n",
      "[88]\tvalid_0's l2: 9.81856\n",
      "[89]\tvalid_0's l2: 9.82204\n",
      "[90]\tvalid_0's l2: 9.79994\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's l2: 9.69879\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "\n",
    "print(\"Boston Housing: regression\")\n",
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=201612\n",
    ")\n",
    "\n",
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "# LightGBM parameters\n",
    "params = {\n",
    "        'task' : 'train',\n",
    "        'boosting_type' : 'gbdt',\n",
    "        'objective' : 'regression',\n",
    "        'metric' : {'l2'},\n",
    "        'num_leaves' : 31,\n",
    "        'learning_rate' : 0.1,\n",
    "        'feature_fraction' : 0.9,\n",
    "        'bagging_fraction' : 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose' : 0\n",
    "}\n",
    "\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "            lgb_train,\n",
    "            num_boost_round=100,\n",
    "            valid_sets=lgb_eval,\n",
    "            early_stopping_rounds=10)\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
